{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tutorials-for-CS-stuff","text":"<p>This will be a repo for CS-related problems and issues such as setting up a Conda environment or setting up a virtual environment using Python. I\u2019ll add those tutorials for future use here. Most of it is AI generated to write clear instructions.</p>"},{"location":"#index-of-tutorials","title":"\ud83d\udcda Index of Tutorials","text":"<ul> <li>\ud83d\ude80 GPU Setup for Jupyter Notebook</li> <li>\ud83d\udd25 Stress testing GPU in jupyter notebook</li> <li>\ud83c\udf10 Setting Up a Virtual Environment in Python</li> <li>\ud83d\ude80 Gradcam plus plus tutorial</li> </ul>"},{"location":"#concepts-in-programming","title":"\ud83d\udcda Concepts in Programming:","text":"<ul> <li>What is OOP in programming? (explained using python)</li> <li>What the heck is a dictionary? (explained using python)</li> </ul>"},{"location":"GradCAMPlusPlus_Tutorial/","title":"\ud83d\udd0d Grad-CAM++ in PyTorch \u2014 Visualizing What Your CNN Sees","text":"<p>Grad-CAM++ is a powerful tool for visualizing where your convolutional neural network is focusing when making a prediction. In this tutorial, we walk through a full implementation of Grad-CAM++ using PyTorch, explain each step, and visualize the result.</p>"},{"location":"GradCAMPlusPlus_Tutorial/#what-this-does","title":"\ud83d\udce6 What This Does","text":"<p>This repo provides a <code>GradCAMPlusPlus</code> class that: - Hooks into the CNN\u2019s target convolutional layer. - Computes gradients and activations for the target class. - Generates class-specific heatmaps. - Visualizes attention over the original image.</p>"},{"location":"GradCAMPlusPlus_Tutorial/#what-is-grad-cam","title":"\ud83e\udde0 What is Grad-CAM++?","text":"<p>Grad-CAM++ is an improvement over Grad-CAM. It: - Localizes features better (especially small objects). - Handles multiple relevant regions. - Computes per-pixel importance via higher-order gradients.</p>"},{"location":"GradCAMPlusPlus_Tutorial/#code-overview","title":"\u2705 Code Overview","text":""},{"location":"GradCAMPlusPlus_Tutorial/#required-imports","title":"\ud83d\udcda Required Imports","text":"<pre><code>import torch\nimport torch.nn.functional as F\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"GradCAMPlusPlus_Tutorial/#gradcamplusplus-class","title":"\ud83d\udd27 GradCAMPlusPlus Class","text":"<pre><code>class GradCAMPlusPlus:\n    def __init__(self, model, target_layer):\n        self.model = model.eval()\n        self.target_layer = target_layer\n        self.activations = None\n        self.gradients = None\n        self._register_hooks()\n\n    def _register_hooks(self):\n        def forward_hook(module, input, output):\n            self.activations = output\n\n        def backward_hook(module, grad_input, grad_output):\n            self.gradients = grad_output[0]\n\n        self.target_layer.register_forward_hook(forward_hook)\n        self.target_layer.register_backward_hook(backward_hook)\n\n    def generate_heatmap(self, input_tensor, class_idx=None):\n        input_tensor = input_tensor.requires_grad_()\n        output = self.model(input_tensor)\n\n        if class_idx is None:\n            class_idx = output.argmax().item()\n\n        self.model.zero_grad()\n        class_score = output[0, class_idx]\n        class_score.backward(retain_graph=True)\n\n        grads = self.gradients[0]              # (C, H, W)\n        activations = self.activations[0]      # (C, H, W)\n        grads_power_2 = grads ** 2\n        grads_power_3 = grads ** 3\n\n        sum_activations = torch.sum(activations, dim=(1, 2), keepdim=True)\n        eps = 1e-8\n        alpha_numer = grads_power_2\n        alpha_denom = grads_power_2.mul(2) + sum_activations * grads_power_3\n        alpha_denom = torch.where(alpha_denom != 0.0, alpha_denom, torch.ones_like(alpha_denom) * eps)\n        alphas = alpha_numer / alpha_denom\n        weights = torch.sum(alphas * F.relu(grads), dim=(1, 2))  # (C,)\n\n        # Weight the activations\n        heatmap = torch.sum(weights[:, None, None] * activations, dim=0).cpu().detach().numpy()\n        heatmap = np.maximum(heatmap, 0)\n        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + eps)\n\n        return heatmap, class_idx\n\n\n    def visualize(self, heatmap, original_image, class_idx, colormap=cv2.COLORMAP_JET):\n        # Resize heatmap to match image size\n        heatmap_resized = cv2.resize(heatmap, (original_image.shape[1], original_image.shape[0]))\n        heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), colormap)\n        overlay = cv2.addWeighted(original_image, 0.5, heatmap_colored, 0.5, 0)\n\n        # Plot\n        plt.figure(figsize=(12, 4))\n        plt.subplot(1, 3, 1)\n        plt.imshow(original_image)\n        plt.title(\"Original\")\n\n        plt.subplot(1, 3, 2)\n        plt.imshow(heatmap_resized, cmap='jet')\n        plt.title(\"Grad-CAM\")\n\n        plt.subplot(1, 3, 3)\n        plt.imshow(overlay)\n        plt.title(f\"Overlay (Predicted Class: {class_idx})\")\n        plt.show()\n</code></pre>"},{"location":"GradCAMPlusPlus_Tutorial/#example-usage","title":"\ud83e\uddea Example Usage","text":"<pre><code>gradcam_pp = GradCAMPlusPlus(model, target_layer=model.layer2[1].conv2)\nheatmap, class_idx = gradcam_pp.generate_heatmap(input_tensor)\n\n# Visualize same as before using `original_img`\ngradcam.visualize(heatmap, original_img, class_idx)\n</code></pre>"},{"location":"GradCAMPlusPlus_Tutorial/#output","title":"\ud83c\udfaf Output","text":"<p>You\u2019ll see: - The original image - The Grad-CAM++ attention heatmap - An overlay showing where the model was looking when it predicted the class</p>"},{"location":"GradCAMPlusPlus_Tutorial/#why-this-is-important","title":"\ud83e\udde0 Why This Is Important","text":"<ul> <li>Gives you insights into what your model is focusing on</li> <li>Improves interpretability and debugging</li> <li>Essential for model explainability in real-world applications</li> </ul>"},{"location":"GradCAMPlusPlus_Tutorial/#output_1","title":"\ud83d\udee0\ufe0f Output","text":""},{"location":"Python_Classes%28OOP%29/","title":"1) What is a class?","text":"<p>If you want to build multiple cars, you don't write instructions from scratch everytime---  you use a blueprint</p> In\u00a0[23]: Copied! <pre>class Car:\n  pass\n</pre> class Car:   pass <p>This defined a class called <code>Car</code>. It doesn't do anything yet-- it's just an empty plan.</p> In\u00a0[23]: Copied! <pre>\n</pre> <p>You use the blueprint to create real things --- objects</p> In\u00a0[24]: Copied! <pre>my_car = Car()\n</pre> my_car = Car() <p>Now <code>my_car</code> is an object (or instance) of the <code>Car</code> class. You can make more cars.</p> In\u00a0[25]: Copied! <pre>another_car = Car()\n</pre> another_car = Car() In\u00a0[25]: Copied! <pre>\n</pre> <p>Let's give each car some info, like color or brand.</p> In\u00a0[26]: Copied! <pre>class Car:\n  def __init__(self, brand, color):\n    self.brand = brand\n    self.color = color\n</pre> class Car:   def __init__(self, brand, color):     self.brand = brand     self.color = color <p><code>__init__</code>: Special method that runs when an object is created.</p> <p><code>self</code>: Refers to the current object.</p> <p><code>self.brand = brand</code>: Saves the brand info in the object.</p> In\u00a0[27]: Copied! <pre># Now create a car:\n\nmy_car = Car(\"Toyota\", \"Red\")\nprint(my_car.brand)\nprint(my_car.color)\n</pre> # Now create a car:  my_car = Car(\"Toyota\", \"Red\") print(my_car.brand) print(my_car.color) <pre>Toyota\nRed\n</pre> In\u00a0[27]: Copied! <pre>\n</pre> <p>Classes can do things. Let's add a method.</p> In\u00a0[28]: Copied! <pre>class Car:\n  def __init__(self, brand, color):\n    self.brand = brand\n    self.color = color\n\n  def drive(self):\n    print(f\"The {self.color} {self.brand} is driving\")\n</pre> class Car:   def __init__(self, brand, color):     self.brand = brand     self.color = color    def drive(self):     print(f\"The {self.color} {self.brand} is driving\")  In\u00a0[29]: Copied! <pre># Use the method\n\nmy_car = Car(\"Honda\", \"white\")\nmy_car.drive()\n</pre> # Use the method  my_car = Car(\"Honda\", \"white\") my_car.drive() <pre>The white Honda is driving\n</pre> In\u00a0[29]: Copied! <pre>\n</pre> <p>You can store static (info) and make changes:</p> In\u00a0[37]: Copied! <pre>class Car:\n  def __init__(self, brand, color):\n    self.brand = brand\n    self.color = color\n    self.speed = 0\n\n  def accelerate(self):\n    self.speed += 10\n    print(f\"{self.brand} speed is now {self.speed} km/h.\")\n\n  def drive(self):\n    print(f\"{self.brand} is driving\")\n</pre> class Car:   def __init__(self, brand, color):     self.brand = brand     self.color = color     self.speed = 0    def accelerate(self):     self.speed += 10     print(f\"{self.brand} speed is now {self.speed} km/h.\")    def drive(self):     print(f\"{self.brand} is driving\") In\u00a0[38]: Copied! <pre># Use the method again\n\nmy_car = Car(\"Ferrari\", \"Red\")\nmy_car.accelerate()\n</pre> # Use the method again  my_car = Car(\"Ferrari\", \"Red\") my_car.accelerate() <pre>Ferrari speed is now 10 km/h.\n</pre> In\u00a0[39]: Copied! <pre>my_car.accelerate()\n</pre> my_car.accelerate() <pre>Ferrari speed is now 20 km/h.\n</pre> In\u00a0[39]: Copied! <pre>\n</pre> <p>Now you can make new classes based on old ones.</p> In\u00a0[40]: Copied! <pre>class ElectricCar(Car):\n  def charge(self):\n    print(f\"{self.brand} is charging.\")\n</pre> class ElectricCar(Car):   def charge(self):     print(f\"{self.brand} is charging.\") In\u00a0[41]: Copied! <pre># let's call the new class\n\ntesla = ElectricCar(\"Tesla\", \"black\")\ntesla.charge()\n</pre> # let's call the new class  tesla = ElectricCar(\"Tesla\", \"black\") tesla.charge() <pre>Tesla is charging.\n</pre> In\u00a0[42]: Copied! <pre>tesla.accelerate()\n</pre> tesla.accelerate() <pre>Tesla speed is now 10 km/h.\n</pre> In\u00a0[43]: Copied! <pre>tesla.drive()\n</pre> tesla.drive() <pre>Tesla is driving\n</pre> In\u00a0[43]: Copied! <pre>\n</pre> In\u00a0[44]: Copied! <pre>class Animal:\n  def speak(self):\n    print(\"some sound\")\n\nclass Dog(Animal):\n  def speak(self):\n    print(\"woof!\")\n\nclass Cat(Animal):\n  def speak(self):\n    print(\"Meow!\")\n</pre> class Animal:   def speak(self):     print(\"some sound\")  class Dog(Animal):   def speak(self):     print(\"woof!\")  class Cat(Animal):   def speak(self):     print(\"Meow!\")  In\u00a0[45]: Copied! <pre>animals = [Dog(), Cat(), Animal()]\nfor a in animals:\n  a.speak()\n</pre> animals = [Dog(), Cat(), Animal()] for a in animals:   a.speak() <pre>woof!\nMeow!\nsome sound\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>Encapsulation means hiding the internal details of how an object works and exposing only what's necessary through public methods.</p> <p>It helps:</p> <ul> <li><p>Prevent accidental changes to internal data</p> </li> <li><p>Control access with getter/setter methods</p> </li> <li><p>Make code easier to maintain and debug</p> </li> </ul> In\u00a0[60]: Copied! <pre>class BankAccount:\n  def __init__(self, balance):\n    self.__balance = balance # Private variable\n\n  def deposit(self, amount):\n    self.__balance += amount\n\n  def get_balance(self):\n    return self.__balance\n</pre> class BankAccount:   def __init__(self, balance):     self.__balance = balance # Private variable    def deposit(self, amount):     self.__balance += amount    def get_balance(self):     return self.__balance In\u00a0[61]: Copied! <pre>acct = BankAccount(100)\nacct.deposit(50)\nprint(acct.get_balance())\n</pre> acct = BankAccount(100) acct.deposit(50) print(acct.get_balance()) <pre>150\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Python_Classes%28OOP%29/#1-what-is-a-class","title":"1) What is a class?\u00b6","text":""},{"location":"Python_Classes%28OOP%29/#2-creating-an-object","title":"2) Creating an Object\u00b6","text":""},{"location":"Python_Classes%28OOP%29/#3-add-data-with-the-__init__-method","title":"3) Add Data with the <code>__init__</code> Method\u00b6","text":""},{"location":"Python_Classes%28OOP%29/#4-add-behavior-methods","title":"4) Add Behavior (Methods)\u00b6","text":""},{"location":"Python_Classes%28OOP%29/#5-add-more-logic","title":"5) Add more Logic\u00b6","text":""},{"location":"Python_Classes%28OOP%29/#6-inheritance","title":"6) Inheritance\u00b6","text":""},{"location":"Python_Classes%28OOP%29/#7-polymorphism-same-method-different-behavior","title":"7) Polymorphism (Same Method, Different Behavior)\u00b6","text":""},{"location":"Python_Classes%28OOP%29/#so-does-dog-or-cat-overwrite-animal","title":"\ud83e\udd14 So Does Dog or Cat Overwrite Animal?\u00b6","text":"<p>Not exactly. Here's what actually happens:</p> <p>The Dog class inherits from Animal, meaning it starts with all of Animal's attributes and methods.</p> <p>When you define <code>speak()</code> again in Dog, this is called overriding the method.</p> <p>It does not overwrite the method in Animal; it replaces it only for objects of type Dog.</p> <p>So when Python sees <code>a.speak()</code>:</p> <p>It checks the actual class of a.</p> <p>If a is a Dog, it checks if Dog has a <code>speak()</code> method.</p> <p>If found, it runs that and ignores the parent version.</p> <p>If not found, it moves up to the parent, Animal, and uses that version.</p>"},{"location":"Python_Classes%28OOP%29/#visualizing-the-lookup-method-resolution-order-mro","title":"\ud83e\uddec Visualizing the Lookup (Method Resolution Order - MRO)\u00b6","text":"<pre><code>plaintext\nDog().speak()\n\u2193\nLook in Dog \u2192 Found! Use Dog's speak()\n\n\nCat().speak()\n\u2193\nLook in Cat \u2192 Found! Use Cat's speak()\n\nAnimal().speak()\n\u2193\nLook in Animal \u2192 Found! Use Animal's speak()\n\n\u2705 Key Concept: Method Overriding \u2260 Overwriting\nAnimal.speak() still exists.\n\n</code></pre> <p>Dog and Cat just override it when their own version is called.</p> <p>This is the power of polymorphism\u2014different behaviors for the same method name depending on the actual object type.</p>"},{"location":"Python_Classes%28OOP%29/#8-encapsulation","title":"8) Encapsulation\u00b6","text":""},{"location":"Python_Classes%28OOP%29/#object-oriented-programming-core-pillars-oop-summary","title":"\u2705 Object-Oriented Programming Core Pillars (OOP Summary)\u00b6","text":"<p>Encapsulation \u2013 Hiding the data (like private balance)</p> <p>Inheritance \u2013 Child class inherits from a parent</p> <p>Polymorphism \u2013 Same method name, different behavior</p> <p>Abstraction \u2013 Hiding complexity and showing only essentials</p>"},{"location":"Testing_GPU_in_Jupyter/","title":"Testing GPU in Jupyter","text":"In\u00a0[1]: Copied! <pre>import torch\nprint(torch.__version__)\nprint(torch.version.cuda)\nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(0))\n</pre> import torch print(torch.__version__) print(torch.version.cuda) print(torch.cuda.is_available()) print(torch.cuda.get_device_name(0))  <pre>2.4.1\n11.8\nTrue\nNVIDIA GeForce RTX 4090 Laptop GPU\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[26]: Copied! <pre>pip install GPUtil\n</pre> pip install GPUtil <pre>Collecting GPUtil\n  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nBuilding wheels for collected packages: GPUtil\n  Building wheel for GPUtil (setup.py): started\n  Building wheel for GPUtil (setup.py): finished with status 'done'\n  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7401 sha256=232218d22e076a53c47b904dde4379881068093ebbfa96d86b248fb36e3f54d0\n  Stored in directory: c:\\users\\abhis\\appdata\\local\\pip\\cache\\wheels\\ba\\03\\bb\\7a97840eb54479b328672e15a536e49dc60da200fb21564d53\nSuccessfully built GPUtil\nInstalling collected packages: GPUtil\nSuccessfully installed GPUtil-1.4.0\nNote: you may need to restart the kernel to use updated packages.\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[27]: Copied! <pre>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nimport time\nimport numpy as np\nimport GPUtil  # Optional, for memory usage\n\n# \u2705 Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# \u2705 Create synthetic image dataset (28x28 like MNIST)\nX = torch.randn(10000, 1, 28, 28)\ny = torch.randint(0, 10, (10000,))\n\ndataset = TensorDataset(X, y)\nloader = DataLoader(dataset, batch_size=128, shuffle=True)\n\n# \u2705 Define a small CNN\nclass TestNet(nn.Module):\n    def __init__(self):\n        super(TestNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\nmodel = TestNet().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# \u2705 Train and time each epoch\nepochs = 5\ntotal_start = time.time()\n\nfor epoch in range(epochs):\n    start = time.time()\n    model.train()\n    total_loss = 0\n    correct = 0\n\n    for inputs, labels in loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        pred = outputs.argmax(dim=1)\n        correct += (pred == labels).sum().item()\n\n    end = time.time()\n    accuracy = correct / len(dataset)\n    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.2f} - Accuracy: {accuracy:.4f} - Time: {end - start:.2f}s\")\n\ntotal_end = time.time()\nprint(f\"\\n\u23f1\ufe0f Total Training Time: {total_end - total_start:.2f}s\")\n\n# \u2705 (Optional) Show GPU memory stats\ntry:\n    gpus = GPUtil.getGPUs()\n    for gpu in gpus:\n        print(f\"\\n\ud83d\udcca GPU Utilization Report for {gpu.name}\")\n        print(f\"  Load       : {gpu.load * 100:.1f}%\")\n        print(f\"  Memory Used: {gpu.memoryUsed} MB / {gpu.memoryTotal} MB\")\n        print(f\"  Temp       : {gpu.temperature} \u00b0C\")\nexcept:\n    print(\"Install GPUtil via: pip install gputil\")\n</pre> import torch import torch.nn as nn import torch.nn.functional as F from torch.utils.data import DataLoader, TensorDataset import time import numpy as np import GPUtil  # Optional, for memory usage  # \u2705 Use GPU if available device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") print(f\"Using device: {device}\")  # \u2705 Create synthetic image dataset (28x28 like MNIST) X = torch.randn(10000, 1, 28, 28) y = torch.randint(0, 10, (10000,))  dataset = TensorDataset(X, y) loader = DataLoader(dataset, batch_size=128, shuffle=True)  # \u2705 Define a small CNN class TestNet(nn.Module):     def __init__(self):         super(TestNet, self).__init__()         self.conv1 = nn.Conv2d(1, 32, kernel_size=3)         self.conv2 = nn.Conv2d(32, 64, kernel_size=3)         self.fc1 = nn.Linear(64 * 12 * 12, 128)         self.fc2 = nn.Linear(128, 10)      def forward(self, x):         x = F.relu(self.conv1(x))         x = F.relu(self.conv2(x))         x = F.max_pool2d(x, 2)         x = torch.flatten(x, 1)         x = F.relu(self.fc1(x))         return self.fc2(x)  model = TestNet().to(device) optimizer = torch.optim.Adam(model.parameters(), lr=0.001) criterion = nn.CrossEntropyLoss()  # \u2705 Train and time each epoch epochs = 5 total_start = time.time()  for epoch in range(epochs):     start = time.time()     model.train()     total_loss = 0     correct = 0      for inputs, labels in loader:         inputs, labels = inputs.to(device), labels.to(device)          optimizer.zero_grad()         outputs = model(inputs)         loss = criterion(outputs, labels)         loss.backward()         optimizer.step()          total_loss += loss.item()         pred = outputs.argmax(dim=1)         correct += (pred == labels).sum().item()      end = time.time()     accuracy = correct / len(dataset)     print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.2f} - Accuracy: {accuracy:.4f} - Time: {end - start:.2f}s\")  total_end = time.time() print(f\"\\n\u23f1\ufe0f Total Training Time: {total_end - total_start:.2f}s\")  # \u2705 (Optional) Show GPU memory stats try:     gpus = GPUtil.getGPUs()     for gpu in gpus:         print(f\"\\n\ud83d\udcca GPU Utilization Report for {gpu.name}\")         print(f\"  Load       : {gpu.load * 100:.1f}%\")         print(f\"  Memory Used: {gpu.memoryUsed} MB / {gpu.memoryTotal} MB\")         print(f\"  Temp       : {gpu.temperature} \u00b0C\") except:     print(\"Install GPUtil via: pip install gputil\")  <pre>Using device: cuda\nEpoch 1/5 - Loss: 182.64 - Accuracy: 0.0995 - Time: 1.88s\nEpoch 2/5 - Loss: 181.89 - Accuracy: 0.1013 - Time: 0.77s\nEpoch 3/5 - Loss: 181.76 - Accuracy: 0.1089 - Time: 0.79s\nEpoch 4/5 - Loss: 180.32 - Accuracy: 0.1433 - Time: 0.79s\nEpoch 5/5 - Loss: 173.15 - Accuracy: 0.2093 - Time: 0.80s\n\n\u23f1\ufe0f Total Training Time: 5.03s\n\n\ud83d\udcca GPU Utilization Report for NVIDIA GeForce RTX 4090 Laptop GPU\n  Load       : 32.0%\n  Memory Used: 1208.0 MB / 16376.0 MB\n  Temp       : 49.0 \u00b0C\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[29]: Copied! <pre>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport time\nimport GPUtil\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"\ud83d\udda5\ufe0f Using device: {device}\")\n\n# \u2705 Load CIFAR-10 dataset (auto-downloads)\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntrain_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n\n# \u2705 Load pretrained ResNet18 and adapt it\nresnet18 = torchvision.models.resnet18(weights=None)  # or use weights=\"DEFAULT\" for pretrained\nresnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\nmodel = resnet18.to(device)\n\n# \u2705 Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# \u2705 Train for multiple epochs\nepochs = 20\ntotal_start = time.time()\n\nfor epoch in range(epochs):\n    start = time.time()\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    end = time.time()\n    accuracy = 100 * correct / total\n    print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {running_loss:.2f} - Accuracy: {accuracy:.2f}% - Time: {end - start:.2f}s\")\n\ntotal_end = time.time()\nprint(f\"\\n\u23f1\ufe0f Total Training Time: {total_end - total_start:.2f}s\")\n\n# \u2705 GPU stats\ntry:\n    gpus = GPUtil.getGPUs()\n    for gpu in gpus:\n        print(f\"\\n\ud83d\udcca GPU Stats for {gpu.name}\")\n        print(f\"  Load       : {gpu.load * 100:.1f}%\")\n        print(f\"  Memory Used: {gpu.memoryUsed} MB / {gpu.memoryTotal} MB\")\n        print(f\"  Temp       : {gpu.temperature} \u00b0C\")\nexcept:\n    print(\"Install GPUtil for GPU stats: pip install gputil\")\n</pre> import torch import torch.nn as nn import torch.optim as optim import torchvision import torchvision.transforms as transforms import time import GPUtil  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") print(f\"\ud83d\udda5\ufe0f Using device: {device}\")  # \u2705 Load CIFAR-10 dataset (auto-downloads) transform = transforms.Compose([     transforms.ToTensor(),     transforms.Normalize((0.5,), (0.5,)) ])  train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)  # \u2705 Load pretrained ResNet18 and adapt it resnet18 = torchvision.models.resnet18(weights=None)  # or use weights=\"DEFAULT\" for pretrained resnet18.fc = nn.Linear(resnet18.fc.in_features, 10) model = resnet18.to(device)  # \u2705 Loss and optimizer criterion = nn.CrossEntropyLoss() optimizer = optim.Adam(model.parameters(), lr=0.001)  # \u2705 Train for multiple epochs epochs = 20 total_start = time.time()  for epoch in range(epochs):     start = time.time()     model.train()     running_loss = 0.0     correct = 0     total = 0      for i, data in enumerate(train_loader, 0):         inputs, labels = data[0].to(device), data[1].to(device)          optimizer.zero_grad()         outputs = model(inputs)         loss = criterion(outputs, labels)         loss.backward()         optimizer.step()          running_loss += loss.item()         _, predicted = torch.max(outputs.data, 1)         total += labels.size(0)         correct += (predicted == labels).sum().item()      end = time.time()     accuracy = 100 * correct / total     print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {running_loss:.2f} - Accuracy: {accuracy:.2f}% - Time: {end - start:.2f}s\")  total_end = time.time() print(f\"\\n\u23f1\ufe0f Total Training Time: {total_end - total_start:.2f}s\")  # \u2705 GPU stats try:     gpus = GPUtil.getGPUs()     for gpu in gpus:         print(f\"\\n\ud83d\udcca GPU Stats for {gpu.name}\")         print(f\"  Load       : {gpu.load * 100:.1f}%\")         print(f\"  Memory Used: {gpu.memoryUsed} MB / {gpu.memoryTotal} MB\")         print(f\"  Temp       : {gpu.temperature} \u00b0C\") except:     print(\"Install GPUtil for GPU stats: pip install gputil\")  <pre>\ud83d\udda5\ufe0f Using device: cuda\nFiles already downloaded and verified\nEpoch [1/20] - Loss: 533.86 - Accuracy: 50.78% - Time: 36.46s\nEpoch [2/20] - Loss: 376.90 - Accuracy: 65.90% - Time: 35.29s\nEpoch [3/20] - Loss: 305.69 - Accuracy: 72.57% - Time: 36.22s\nEpoch [4/20] - Loss: 257.21 - Accuracy: 76.83% - Time: 34.88s\nEpoch [5/20] - Loss: 216.65 - Accuracy: 80.31% - Time: 36.07s\nEpoch [6/20] - Loss: 179.43 - Accuracy: 83.93% - Time: 35.99s\nEpoch [7/20] - Loss: 146.47 - Accuracy: 86.85% - Time: 36.28s\nEpoch [8/20] - Loss: 120.00 - Accuracy: 89.07% - Time: 36.39s\nEpoch [9/20] - Loss: 96.59 - Accuracy: 91.29% - Time: 36.93s\nEpoch [10/20] - Loss: 79.86 - Accuracy: 92.80% - Time: 37.09s\nEpoch [11/20] - Loss: 63.81 - Accuracy: 94.24% - Time: 35.98s\nEpoch [12/20] - Loss: 54.07 - Accuracy: 95.24% - Time: 35.58s\nEpoch [13/20] - Loss: 45.52 - Accuracy: 95.99% - Time: 38.45s\nEpoch [14/20] - Loss: 43.47 - Accuracy: 96.04% - Time: 37.86s\nEpoch [15/20] - Loss: 40.34 - Accuracy: 96.41% - Time: 35.80s\nEpoch [16/20] - Loss: 34.26 - Accuracy: 96.90% - Time: 37.96s\nEpoch [17/20] - Loss: 32.94 - Accuracy: 97.06% - Time: 35.31s\nEpoch [18/20] - Loss: 32.16 - Accuracy: 97.11% - Time: 36.67s\nEpoch [19/20] - Loss: 24.70 - Accuracy: 97.82% - Time: 35.57s\nEpoch [20/20] - Loss: 27.82 - Accuracy: 97.56% - Time: 35.39s\n\n\u23f1\ufe0f Total Training Time: 726.16s\n\n\ud83d\udcca GPU Stats for NVIDIA GeForce RTX 4090 Laptop GPU\n  Load       : 37.0%\n  Memory Used: 1593.0 MB / 16376.0 MB\n  Temp       : 51.0 \u00b0C\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"Testing_GPU_in_Jupyter/#running-the-jupyter-notebook-on-gpu","title":"Running the jupyter notebook on GPU\u00b6","text":""},{"location":"Testing_GPU_in_Jupyter/#gputil-is-a-python-module-for-getting-the-gpu-status-from-nvida-gpus-using-nvidia-smi","title":"GPUtil is a Python module for getting the GPU status from NVIDA GPUs using nvidia-smi.\u00b6","text":""},{"location":"Testing_GPU_in_Jupyter/#gpu-stress-test-benchmark-program-pytorch","title":"\u2705 GPU Stress Test &amp; Benchmark Program (PyTorch)\u00b6","text":"<p>This script:</p> <ul> <li><p>Trains a simple CNN on a synthetic dataset (no downloads needed).</p> </li> <li><p>Runs on GPU (if available).</p> </li> <li><p>Prints training time per epoch, GPU memory usage, and total throughput.</p> </li> </ul>"},{"location":"Testing_GPU_in_Jupyter/#what-youll-see","title":"\ud83d\udcc8 What You'll See\u00b6","text":"<ul> <li><p>Epoch-wise speed (in seconds).</p> </li> <li><p>Accuracy (based on synthetic labels \u2014 so low is okay).</p> </li> <li><p>Total GPU training time.</p> </li> <li><p>Memory usage and GPU load (optional with GPUtil).</p> </li> </ul>"},{"location":"Testing_GPU_in_Jupyter/#lets-push-your-gpu-harder-by-training-a-larger-and-deeper-model-on-a-real-dataset-such-as-cifar-10-with-resnet18","title":"let\u2019s push your GPU harder by training a larger and deeper model on a real dataset, such as CIFAR-10 with ResNet18.\u00b6","text":"<p>This test will:</p> <ul> <li><p>Load CIFAR-10 from torchvision.datasets (~60,000 images).</p> </li> <li><p>Use ResNet18 (a popular, deeper CNN).</p> </li> <li><p>Train for several epochs to saturate GPU load.</p> </li> <li><p>Show timing, GPU usage, and performance metrics.</p> </li> </ul>"},{"location":"Testing_GPU_in_Jupyter/#what-youll-get","title":"\ud83e\udde0 What You\u2019ll Get\u00b6","text":"<ul> <li><p>Total training time per epoch (heavier load).</p> </li> <li><p>Accuracy improvement over time.</p> </li> <li><p>GPU memory and utilization stats.</p> </li> <li><p>Significant stress on your GPU (compared to synthetic tests).</p> </li> </ul>"},{"location":"dictionary/","title":"\ud83e\udde0 Understanding Python Dictionaries","text":"<p>Python dictionaries are a fundamental and powerful data structure that allows you to store and manipulate data using key-value pairs.</p>"},{"location":"dictionary/#what-is-a-python-dictionary","title":"\ud83d\udcd8 What Is a Python Dictionary?","text":"<p>A dictionary in Python is a mutable, unordered collection of items. Each item consists of a key and its associated value. Keys must be unique and immutable (like strings, numbers, or tuples), while values can be of any data type.</p> <p>Think of a real-world dictionary: you look up a word (the key) to find its definition (the value). Similarly, in Python:</p> <pre><code>my_dict = {\n    \"name\": \"Alice\",\n    \"age\": 30,\n    \"city\": \"New York\"\n}\n</code></pre> <p>Here, <code>\"name\"</code>, <code>\"age\"</code>, and <code>\"city\"</code> are keys, and their corresponding values are <code>\"Alice\"</code>, <code>30</code>, and <code>\"New York\"</code>.</p>"},{"location":"dictionary/#creating-dictionaries","title":"\ud83d\udee0\ufe0f Creating Dictionaries","text":""},{"location":"dictionary/#1-using-curly-braces","title":"1. Using Curly Braces <code>{}</code>","text":"<pre><code>person = {\"name\": \"Bob\", \"age\": 25}\n</code></pre>"},{"location":"dictionary/#2-using-the-dict-constructor","title":"2. Using the <code>dict()</code> Constructor","text":"<pre><code>person = dict(name=\"Bob\", age=25)\n</code></pre>"},{"location":"dictionary/#3-creating-an-empty-dictionary","title":"3. Creating an Empty Dictionary","text":"<pre><code>empty_dict = {}\n# or\nempty_dict = dict()\n</code></pre>"},{"location":"dictionary/#accessing-and-modifying-items","title":"\ud83d\udd0d Accessing and Modifying Items","text":""},{"location":"dictionary/#accessing-values","title":"Accessing Values","text":"<pre><code>print(person[\"name\"])  # Outputs: Bob\n</code></pre>"},{"location":"dictionary/#adding-or-updating-items","title":"Adding or Updating Items","text":"<pre><code>person[\"city\"] = \"Los Angeles\"  # Adds a new key-value pair\nperson[\"age\"] = 26              # Updates the existing value\n</code></pre>"},{"location":"dictionary/#removing-items","title":"Removing Items","text":"<pre><code>del person[\"age\"]               # Removes the key 'age'\ncity = person.pop(\"city\")       # Removes 'city' and returns its value\n</code></pre>"},{"location":"dictionary/#iterating-through-a-dictionary","title":"\ud83d\udd04 Iterating Through a Dictionary","text":""},{"location":"dictionary/#iterating-over-keys","title":"Iterating Over Keys","text":"<pre><code>for key in person:\n    print(key)\n</code></pre>"},{"location":"dictionary/#iterating-over-values","title":"Iterating Over Values","text":"<pre><code>for value in person.values():\n    print(value)\n</code></pre>"},{"location":"dictionary/#iterating-over-key-value-pairs","title":"Iterating Over Key-Value Pairs","text":"<pre><code>for key, value in person.items():\n    print(f\"{key}: {value}\")\n</code></pre>"},{"location":"dictionary/#useful-dictionary-methods","title":"\ud83e\uddf0 Useful Dictionary Methods","text":"<ul> <li><code>get(key, default)</code> \u2013 Returns the value for <code>key</code> if <code>key</code> is in the dictionary; otherwise, returns <code>default</code>.</li> <li><code>keys()</code> \u2013 Returns a view object of all keys.</li> <li><code>values()</code> \u2013 Returns a view object of all values.</li> <li><code>items()</code> \u2013 Returns a view object of all key-value pairs.</li> <li><code>update(other_dict)</code> \u2013 Updates the dictionary with key-value pairs from <code>other_dict</code>.</li> <li><code>clear()</code> \u2013 Removes all items from the dictionary.</li> </ul>"},{"location":"dictionary/#dictionary-comprehensions","title":"\ud83e\udde0 Dictionary Comprehensions","text":"<p>Dictionary comprehensions provide a concise way to create dictionaries:</p> <pre><code>squares = {x: x**2 for x in range(5)}\nprint(squares)  # Outputs: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}\n</code></pre> <p>You can also add conditions:</p> <pre><code>even_squares = {x: x**2 for x in range(10) if x % 2 == 0}\n</code></pre>"},{"location":"dictionary/#practical-example","title":"\ud83e\uddea Practical Example","text":"<p>Let's say you have a list of fruits and their quantities:</p> <pre><code>fruits = [(\"apple\", 2), (\"banana\", 3), (\"orange\", 1)]\nfruit_dict = dict(fruits)\nprint(fruit_dict)\n</code></pre> <p>This will output:</p> <pre><code>{'apple': 2, 'banana': 3, 'orange': 1}\n</code></pre>"},{"location":"dictionary/#further-learning","title":"\ud83d\udcda Further Learning","text":"<ul> <li>Dictionaries in Python</li> <li>Python Dictionaries: A Comprehensive Tutorial (with 52 Code Examples)</li> <li>Python Dictionary Comprehensions: How and When to Use Them</li> <li>Python Tutorial for Beginners 5: Dictionaries</li> </ul>"},{"location":"dictionary/#advanced-python-dictionary-techniques-in-leetcode","title":"\ud83e\udde0 Advanced Python Dictionary Techniques in LeetCode","text":"<p>Python dictionaries are versatile tools in solving complex algorithmic problems. Below are advanced techniques and patterns demonstrating their power:</p>"},{"location":"dictionary/#1-hash-maps-for-constant-time-lookups","title":"1. Hash Maps for Constant-Time Lookups","text":"<p>Problem: Two Sum Concept: Use a dictionary to store elements and their indices for O(1) lookups.</p> <pre><code>def two_sum(nums, target):\n    num_map = {}\n    for i, num in enumerate(nums):\n        complement = target - num\n        if complement in num_map:\n            return [num_map[complement], i]\n        num_map[num] = i\n</code></pre>"},{"location":"dictionary/#2-counting-frequencies-with-collectionscounter","title":"2. Counting Frequencies with <code>collections.Counter</code>","text":"<p>Problem: Uncommon Words from Two Sentences Concept: Utilize <code>Counter</code> to count word frequencies efficiently.</p> <pre><code>from collections import Counter\n\ndef uncommon_from_sentences(s1, s2):\n    count = Counter((s1 + \" \" + s2).split())\n    return [word for word in count if count[word] == 1]\n</code></pre>"},{"location":"dictionary/#3-grouping-anagrams","title":"3. Grouping Anagrams","text":"<p>Problem: Group Anagrams Concept: Use a dictionary with sorted word tuples as keys to group anagrams.</p> <pre><code>from collections import defaultdict\n\ndef group_anagrams(strs):\n    anagrams = defaultdict(list)\n    for word in strs:\n        key = tuple(sorted(word))\n        anagrams[key].append(word)\n    return list(anagrams.values())\n</code></pre>"},{"location":"dictionary/#4-sliding-window-with-hash-maps","title":"4. Sliding Window with Hash Maps","text":"<p>Problem: Longest Substring Without Repeating Characters Concept: Maintain a sliding window and use a dictionary to track characters' indices.</p> <pre><code>def length_of_longest_substring(s):\n    char_index = {}\n    left = max_length = 0\n    for right, char in enumerate(s):\n        if char in char_index and char_index[char] &gt;= left:\n            left = char_index[char] + 1\n        char_index[char] = right\n        max_length = max(max_length, right - left + 1)\n    return max_length\n</code></pre>"},{"location":"dictionary/#5-topological-sorting-with-dictionaries","title":"5. Topological Sorting with Dictionaries","text":"<p>Problem: Alien Dictionary Concept: Build adjacency lists and in-degree counts using dictionaries for topological sorting.</p> <pre><code>from collections import defaultdict, deque\n\ndef alien_order(words):\n    adj = defaultdict(set)\n    in_degree = {char: 0 for word in words for char in word}\n\n    for first, second in zip(words, words[1:]):\n        for c1, c2 in zip(first, second):\n            if c1 != c2:\n                if c2 not in adj[c1]:\n                    adj[c1].add(c2)\n                    in_degree[c2] += 1\n                break\n        else:\n            if len(second) &lt; len(first):\n                return \"\"\n\n    queue = deque([c for c in in_degree if in_degree[c] == 0])\n    order = []\n    while queue:\n        c = queue.popleft()\n        order.append(c)\n        for neighbor in adj[c]:\n            in_degree[neighbor] -= 1\n            if in_degree[neighbor] == 0:\n                queue.append(neighbor)\n\n    return \"\".join(order) if len(order) == len(in_degree) else \"\"\n</code></pre>"},{"location":"dictionary/#6-dynamic-programming-with-memoization","title":"6. Dynamic Programming with Memoization","text":"<p>Problem: Word Break Concept: Use a dictionary to memoize results of subproblems to avoid redundant computations.</p> <pre><code>def word_break(s, word_dict):\n    memo = {}\n\n    def can_break(start):\n        if start == len(s):\n            return True\n        if start in memo:\n            return memo[start]\n        for end in range(start + 1, len(s) + 1):\n            if s[start:end] in word_dict and can_break(end):\n                memo[start] = True\n                return True\n        memo[start] = False\n        return False\n\n    return can_break(0)\n</code></pre>"},{"location":"github_actions_guide/","title":"GitHub Actions: Automate Your Workflow","text":"<p>GitHub Actions is a powerful continuous integration and continuous delivery (CI/CD) platform that allows you to automate, customize, and execute your software development workflows directly within your GitHub repository. You can build, test, and deploy your code whenever you push changes, open pull requests, or create releases. This tight integration streamlines development and reduces context switching.</p>"},{"location":"github_actions_guide/#what-is-github-actions","title":"What Is GitHub Actions?","text":"<ul> <li>Workflows: Defined in YAML files under <code>.github/workflows/</code>, workflows consist of one or more jobs that run on specified events (e.g., <code>push</code>, <code>pull_request</code>, <code>schedule</code>).</li> <li>Jobs and Steps: Each workflow contains jobs, which are units of work that execute on a runner. Jobs consist of steps, which can run shell commands or reuse existing Actions from the Marketplace.</li> <li>Actions: Reusable commands or scripts packaged into standalone units. You can find thousands of official and community-maintained Actions in the GitHub Marketplace, or write your own.</li> </ul>"},{"location":"github_actions_guide/#key-concepts","title":"Key Concepts","text":"<ol> <li> <p>Events &amp; Triggers    Define when a workflow runs (e.g., on <code>push</code>, <code>pull_request</code>, or custom events).</p> </li> <li> <p>Runners    Virtual machines (Linux, Windows, macOS) or self-hosted machines where your jobs execute.</p> </li> <li> <p>Marketplace    Discover and integrate actions for tasks like setting up environments, testing, linting, and deployment.</p> </li> </ol>"},{"location":"github_actions_guide/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Continuous Integration: Automatically build and test every commit and pull request.</li> <li>Continuous Deployment: Deploy successful builds to staging or production environments.</li> <li>Infrastructure Automation: Provision or configure cloud resources via Infrastructure-as-Code tools.</li> <li>Workflow Orchestration: Automate issue labeling, triage, notifications, and more.</li> </ul>"},{"location":"github_actions_guide/#getting-started","title":"Getting Started","text":"<ol> <li>Create a directory <code>.github/workflows/</code> in your repository.</li> <li>Add a workflow file (e.g., <code>ci.yml</code>) with a trigger, job definitions, and steps.</li> <li>Commit and push to GitHub\u2014your workflow will automatically run and appear in the Actions tab.</li> <li>Monitor workflow runs and view logs directly in GitHub to debug and iterate.</li> </ol>"},{"location":"github_actions_guide/#sample-code","title":"Sample code:","text":"<pre><code>name: Deploy MkDocs to GitHub Pages\n\non:\n  push:\n    branches:\n      - main  # trigger on pushes to main\n\npermissions:\n  contents: write    # push to repo\n  pages: write       # update GitHub Pages\n  id-token: write    # support Pages token flow\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3                             # pull down your repo :contentReference[oaicite:3]{index=3}\n\n      - name: Set up Python\n        uses: actions/setup-python@v4                         # install Python for mkdocs :contentReference[oaicite:4]{index=4}\n        with:\n          python-version: '3.x'\n\n      - name: Install MkDocs &amp; plugins\n        run: pip install mkdocs-material mkdocs-jupyter       # get mkdocs and jupyter support :contentReference[oaicite:5]{index=5}\n\n      - name: Build site\n        run: mkdocs build --clean                              # render markdown into ./site/ :contentReference[oaicite:6]{index=6}\n\n      - name: Deploy to GitHub Pages\n        uses: peaceiris/actions-gh-pages@v4                   # deploy your ./site/ to gh-pages branch :contentReference[oaicite:7]{index=7}\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./site\n          publish_branch: gh-pages                           # explicitly push to gh-pages :contentReference[oaicite:8]{index=8}\n</code></pre> <p>For detailed documentation and examples, explore the GitHub Actions docs.</p> <p>This guide provides an overview of GitHub Actions and practical steps to start automating your software workflows. </p>"},{"location":"setting_up_jupyter_for_gpu_use/","title":"Setting up jupyter for gpu use","text":""},{"location":"setting_up_jupyter_for_gpu_use/#full-guide-running-jupyter-notebook-on-gpus","title":"\u2705 Full Guide: Running Jupyter Notebook on GPUs","text":"<p>This guide helps you set up Jupyter Notebook with GPU support using Anaconda, CUDA, cuDNN, and deep learning libraries like PyTorch or TensorFlow.</p>"},{"location":"setting_up_jupyter_for_gpu_use/#step-1-install-anaconda","title":"\u2699\ufe0f Step 1: Install Anaconda","text":"<ul> <li> <p>Download and install from:   \ud83d\udc49 https://www.anaconda.com/products/distribution</p> </li> <li> <p>After installation, launch Jupyter Notebook via:</p> </li> </ul> <pre><code>jupyter notebook\n</code></pre> <p>This opens Jupyter Notebook in your browser.</p>"},{"location":"setting_up_jupyter_for_gpu_use/#step-2-install-cuda-toolkit","title":"\u2699\ufe0f Step 2: Install CUDA Toolkit","text":"<p>CUDA enables your Python libraries (e.g., TensorFlow, PyTorch) to run on NVIDIA GPUs.</p> <ul> <li> <p>Download from:   \ud83d\udc49 https://developer.nvidia.com/cuda-downloads</p> </li> <li> <p>Choose the version that matches:</p> </li> <li>Your GPU model</li> <li> <p>Your Operating System</p> </li> <li> <p>To verify your GPU details:</p> </li> </ul> <pre><code>nvidia-smi\n</code></pre>"},{"location":"setting_up_jupyter_for_gpu_use/#step-3-install-cudnn-library","title":"\u2699\ufe0f Step 3: Install cuDNN Library","text":"<p>cuDNN accelerates deep learning on GPUs.</p> <ul> <li> <p>Download from:   \ud83d\udc49 https://developer.nvidia.com/cudnn</p> </li> <li> <p>Match cuDNN version with your installed CUDA version.</p> </li> </ul> <p>After downloading: - Extract the files. - Copy <code>bin/</code>, <code>lib/</code>, and <code>include/</code> folders into your CUDA installation directory (usually <code>/usr/local/cuda/</code> on Linux).</p> <p>\u26a0\ufe0f cuDNN must be manually installed \u2014 not via conda/pip.</p>"},{"location":"setting_up_jupyter_for_gpu_use/#step-4-create-a-conda-environment-python-38","title":"\u2699\ufe0f Step 4: Create a Conda Environment (Python 3.8)","text":"<pre><code>conda create --name gpu_env python=3.8\nconda activate gpu_env\n</code></pre>"},{"location":"setting_up_jupyter_for_gpu_use/#step-5-install-required-packages","title":"\u2699\ufe0f Step 5: Install Required Packages","text":"<p>Choose one of the following options depending on your framework preference:</p>"},{"location":"setting_up_jupyter_for_gpu_use/#option-a-tensorflow-keras-gpu-enabled","title":"\ud83e\udde0 Option A: TensorFlow + Keras (GPU-enabled)","text":"<pre><code>conda install -c anaconda tensorflow-gpu keras-gpu\n</code></pre>"},{"location":"setting_up_jupyter_for_gpu_use/#option-b-pytorch-gpu-enabled-recommended","title":"\ud83d\udd25 Option B: PyTorch (GPU-enabled, recommended)","text":"<pre><code>conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n</code></pre> <p>\u26a0\ufe0f Replace <code>11.8</code> with your actual CUDA version.</p>"},{"location":"setting_up_jupyter_for_gpu_use/#optional-add-data-science-packages","title":"\u2795 Optional: Add data science packages","text":"<pre><code>conda install jupyter numpy pandas matplotlib scikit-learn\n</code></pre>"},{"location":"setting_up_jupyter_for_gpu_use/#step-6-configure-jupyter-to-use-gpu-environment","title":"\u2699\ufe0f Step 6: Configure Jupyter to Use GPU Environment","text":"<pre><code>python -m ipykernel install --user --name gpu_env --display-name \"Python (GPU)\"\n</code></pre> <p>\u2705 This registers the environment as \"Python (GPU)\" in the Jupyter kernel list.</p>"},{"location":"setting_up_jupyter_for_gpu_use/#step-7-launch-jupyter-notebook","title":"\ud83d\ude80 Step 7: Launch Jupyter Notebook","text":"<pre><code>jupyter notebook\n</code></pre> <ul> <li>Click New Notebook</li> <li>Choose the \"Python (GPU)\" kernel</li> </ul>"},{"location":"setting_up_jupyter_for_gpu_use/#step-8-verify-gpu-is-being-used","title":"\u2705 Step 8: Verify GPU is Being Used","text":"<p>Run this in a notebook cell:</p> <pre><code>import torch\ntorch.cuda.is_available()\n</code></pre> <p>Expected Output:</p> <pre><code>True\n</code></pre> <p>If <code>True</code>, your environment is GPU-enabled. \ud83c\udf89</p>"},{"location":"setting_up_jupyter_for_gpu_use/#quick-troubleshooting","title":"\ud83e\udde0 Quick Troubleshooting","text":"Problem Fix <code>torch.cuda.is_available()</code> is <code>False</code> Make sure CUDA and cuDNN are properly installed Kernel not showing in Jupyter Ensure you ran the <code>ipykernel install</code> command Version mismatch / compatibility Match TensorFlow or PyTorch to your CUDA version Model runs slow Check if code is accidentally running on CPU (<code>torch.device(\"cuda\")</code>) <p>Once you configure the versions of CUDA, cudnn and jupyter, you go over steps 7 and 8 again and you should find your notebook running on GPU.</p> <p></p>"},{"location":"setting_up_virtual_env_using_python/","title":"Setting up virtual env using python","text":"<p>Python 3.3+ comes with <code>venv</code> built-in \u2014 no need to install anything else.</p>"},{"location":"setting_up_virtual_env_using_python/#step-by-step-instructions","title":"\ud83d\ude80 Step-by-Step Instructions","text":""},{"location":"setting_up_virtual_env_using_python/#step-1-create-a-virtual-environment","title":"\ud83d\udd39 Step 1: Create a Virtual Environment","text":"<p>Navigate to your project folder:</p> <pre><code>cd path/to/your/project\n</code></pre> <p>Then run:</p> <pre><code>python -m venv venv\n</code></pre> <p>This creates a folder called <code>venv/</code> with a self-contained Python environment.</p>"},{"location":"setting_up_virtual_env_using_python/#step-2-activate-the-environment","title":"\ud83d\udd39 Step 2: Activate the Environment","text":""},{"location":"setting_up_virtual_env_using_python/#on-windows","title":"\ud83e\ude9f On Windows:","text":"<pre><code>venv\\Scripts\\activate\n</code></pre>"},{"location":"setting_up_virtual_env_using_python/#on-linuxmacos","title":"\ud83d\udc27 On Linux/macOS:","text":"<pre><code>source venv/bin/activate\n</code></pre> <p>\u2705 You'll know it's activated if your terminal prompt starts with:</p> <pre><code>(venv)\n</code></pre>"},{"location":"setting_up_virtual_env_using_python/#step-3-install-dependencies","title":"\ud83d\udd39 Step 3: Install Dependencies","text":"<p>Once activated, install your packages using <code>pip</code>:</p> <pre><code>pip install numpy pandas matplotlib\n</code></pre>"},{"location":"setting_up_virtual_env_using_python/#step-4-freeze-your-environment-optional","title":"\ud83d\udd39 Step 4: Freeze Your Environment (Optional)","text":"<p>Save current packages to a file:</p> <pre><code>pip freeze &gt; requirements.txt\n</code></pre> <p>To recreate the environment later:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"setting_up_virtual_env_using_python/#step-5-deactivate-the-environment","title":"\ud83d\udd39 Step 5: Deactivate the Environment","text":"<p>When you're done:</p> <pre><code>deactivate\n</code></pre>"},{"location":"setting_up_virtual_env_using_python/#bonus-tips","title":"\ud83e\udde0 Bonus Tips","text":"Task Command Delete environment Just delete the <code>venv/</code> folder Check where pip installs <code>which pip</code> (mac/Linux), <code>where pip</code> (Windows) Use environment in VSCode It will auto-detect or use <code>Python: Select Interpreter</code>"},{"location":"setting_up_virtual_env_using_python/#tldr-cheat-sheet","title":"\u2705 TL;DR Cheat Sheet","text":"<pre><code># Create environment\npython -m venv venv\n\n# Activate (Linux/macOS)\nsource venv/bin/activate\n\n# Activate (Windows)\nvenv\\Scripts\\activate\n\n# Install packages\npip install -r requirements.txt\n\n# Deactivate\ndeactivate\n</code></pre>"}]}